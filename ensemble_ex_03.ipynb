{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìù Exercise M6.03\n",
    "\n",
    "The aim of this exercise is to:\n",
    "\n",
    "* verifying if a random forest or a gradient-boosting decision tree overfit\n",
    "  if the number of estimators is not properly chosen;\n",
    "* use the early-stopping strategy to avoid adding unnecessary trees, to\n",
    "  get the best generalization performances.\n",
    "\n",
    "We will use the California housing dataset to conduct our experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data, target = fetch_california_housing(return_X_y=True, as_frame=True)\n",
    "target *= 100  # rescale the target in k$\n",
    "data_train, data_test, target_train, target_test = train_test_split(\n",
    "    data, target, random_state=0, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"admonition note alert alert-info\">\n",
    "<p class=\"first admonition-title\" style=\"font-weight: bold;\">Note</p>\n",
    "<p class=\"last\">If you want a deeper overview regarding this dataset, you can refer to the\n",
    "Appendix - Datasets description section at the end of this MOOC.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a gradient boosting decision tree with `max_depth=5` and\n",
    "`learning_rate=0.5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "boost = GradientBoostingRegressor(max_depth=5, learning_rate=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Also create a random forest with fully grown trees by setting `max_depth=None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "forest = RandomForestRegressor(max_depth=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "For both the gradient-boosting and random forest models, create a validation\n",
    "curve using the training set to assess the impact of the number of trees on\n",
    "the performance of each model. Evaluate the list of parameters `param_range =\n",
    "[1, 2, 5, 10, 20, 50, 100]` and use the mean absolute error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "boost_val_curve = validation_curve(boost, data_train, target_train, param_name='n_estimator', param_range=[1, 2, 5, 10, 20, 50, 100], scoring='neg_mean_absolute_error', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8de4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_val_curve = validation_curve(forest, data_train, target_train, param_name='n_estimator', param_range=[1, 2, 5, 10, 20, 50, 100], scoring='neg_mean_absolute_error', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both gradient boosting and random forest models will always improve when\n",
    "increasing the number of trees in the ensemble. However, it will reach a\n",
    "plateau where adding new trees will just make fitting and scoring slower.\n",
    "\n",
    "To avoid adding new unnecessary tree, unlike random-forest gradient-boosting\n",
    "offers an early-stopping option. Internally, the algorithm will use an\n",
    "out-of-sample set to compute the generalization performance of the model at\n",
    "each addition of a tree. Thus, if the generalization performance is not\n",
    "improving for several iterations, it will stop adding trees.\n",
    "\n",
    "Now, create a gradient-boosting model with `n_estimators=1_000`. This number\n",
    "of trees will be too large. Change the parameter `n_iter_no_change` such\n",
    "that the gradient boosting fitting will stop after adding 5 trees that do not\n",
    "improve the overall generalization performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimate the generalization performance of this model again using\n",
    "the `sklearn.metrics.mean_absolute_error` metric but this time using\n",
    "the test set that we held out at the beginning of the notebook.\n",
    "Compare the resulting value with the values observed in the validation\n",
    "curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
